import streamlit as st
import json
from typing import Optional
from .api import APIClient
from .utils import load_prompts, add_log

class MLPGenerator:
    def __init__(self, api_client: APIClient):
        self.api_client = api_client
        self.prompts = load_prompts()

    def generate_mlp(self):
        """ç”ŸæˆMLPå¼€å‘è®¡åˆ’"""
        st.header("MLP å¼€å‘")
        
        # æ£€æŸ¥å…¨å±€äº§å“ä¸­å¿ƒå¥
        if 'product_core_sentence' not in st.session_state:
            st.warning("è¯·å…ˆåœ¨PRç”Ÿæˆæ¨¡å—ç”Ÿæˆäº§å“ä¸­å¿ƒå¥")
            return
            
        # æ˜¾ç¤ºäº§å“ä¸­å¿ƒå¥
        core_sentence = st.session_state.product_core_sentence
        st.markdown("### äº§å“ä¸­å¿ƒå¥")
        
        # åˆå¹¶æ˜¾ç¤ºå®¢æˆ·éœ€æ±‚å’Œè§£å†³æ–¹æ¡ˆï¼Œå¹¶æ·»åŠ é«˜äº®
        if isinstance(core_sentence, dict):
            formatted_core_sentence = (
                f"**å®¢æˆ·éœ€æ±‚ï¼š**`{core_sentence.get('customer_needs', '')}`\n\n"
                f"**è§£å†³æ–¹æ¡ˆï¼š**`{core_sentence.get('solution', '')}`"
            )
            st.markdown(formatted_core_sentence)
            
            # åˆå¹¶æˆå®Œæ•´çš„ä¸­å¿ƒå¥ç”¨äºæç¤ºè¯
            full_core_sentence = (
                f"å®¢æˆ·éœ€æ±‚ï¼š{core_sentence.get('customer_needs', '')}\n"
                f"è§£å†³æ–¹æ¡ˆï¼š{core_sentence.get('solution', '')}"
            )
        else:
            st.error("äº§å“ä¸­å¿ƒå¥æ ¼å¼é”™è¯¯")
            return

        # åˆ›å»ºç”ŸæˆæŒ‰é’®
        if st.button("ç”ŸæˆMLPå¼€å‘è®¡åˆ’", key="generate_mlp"):
            add_log("user", "ğŸ‘‰ ç‚¹å‡»ç”ŸæˆMLPå¼€å‘è®¡åˆ’")
            
            # è·å–mlpæç¤ºè¯
            try:
                prompts = self.prompts
                mlp_prompt = prompts.get("mlp", {}).get("prompt")
                
                if not mlp_prompt:
                    st.error("æœªæ‰¾åˆ°MLPæç¤ºè¯é…ç½®")
                    add_log("error", "âŒ æœªæ‰¾åˆ°MLPæç¤ºè¯é…ç½®")
                    return
                
                # æ„å»ºå®Œæ•´æç¤ºè¯ï¼Œæ›¿æ¢${core_sentence}å ä½ç¬¦
                prompt = mlp_prompt.replace(
                    "${core_sentence}", 
                    full_core_sentence
                )
                
                add_log("info", "ğŸš€ å¼€å§‹ç”ŸæˆMLPå¼€å‘è®¡åˆ’")
                
                # åˆ›å»ºå ä½ç¬¦ç”¨äºæµå¼è¾“å‡º
                response_placeholder = st.empty()
                
                try:
                    # åˆå§‹åŒ–å“åº”æ–‡æœ¬
                    full_response = ""
                    
                    # æµå¼ç”Ÿæˆå†…å®¹
                    for chunk in self.api_client.generate_content_stream(prompt):
                        full_response += chunk
                        # å®æ—¶æ›´æ–°æ˜¾ç¤ºçš„å†…å®¹
                        response_placeholder.markdown(full_response)
                    
                    add_log("info", "âœ¨ MLPå¼€å‘è®¡åˆ’ç”Ÿæˆå®Œæˆ")
                    
                except Exception as e:
                    error_msg = f"ç”ŸæˆMLPå¼€å‘è®¡åˆ’æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
                    st.error(error_msg)
                    add_log("error", f"âŒ {error_msg}")
                
            except Exception as e:
                error_msg = f"è¯»å–æç¤ºè¯é…ç½®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
                st.error(error_msg)
                add_log("error", f"âŒ {error_msg}") 